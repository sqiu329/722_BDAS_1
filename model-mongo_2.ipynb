{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('722-model').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adm0_id: integer (nullable = true)\n",
      " |-- adm0_name: string (nullable = true)\n",
      " |-- adm1_id: integer (nullable = true)\n",
      " |-- adm1_name: string (nullable = true)\n",
      " |-- mkt_id: integer (nullable = true)\n",
      " |-- mkt_name: string (nullable = true)\n",
      " |-- cm_id: integer (nullable = true)\n",
      " |-- cm_name: string (nullable = true)\n",
      " |-- cur_id: integer (nullable = true)\n",
      " |-- cur_name: string (nullable = true)\n",
      " |-- pt_id: integer (nullable = true)\n",
      " |-- pt_name: string (nullable = true)\n",
      " |-- um_id: integer (nullable = true)\n",
      " |-- um_name: string (nullable = true)\n",
      " |-- mp_month: integer (nullable = true)\n",
      " |-- mp_year: integer (nullable = true)\n",
      " |-- mp_price_RMB: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1= spark.read.csv(\"./data_mongo.csv\", header=True, inferSchema=True)\n",
    "data1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "  inputCols=['mp_price_RMB'],\n",
    "              outputCol=\"features\")\n",
    "output = assembler.transform(data1)\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"mkt_namexXQ\", outputCol=\"PrivateIndex\")\n",
    "output_fixed = indexer.fit(output).transform(output)\n",
    "final_data = output_fixed.select(\"features\",'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "dtc = DecisionTreeClassifier(labelCol='PrivateIndex',featuresCol='features')\n",
    "train_data,test_data = final_data.randomSplit([0.7,0.3])\n",
    "dtc_model = dtc.fit(train_data)\n",
    "dtc_predictions = dtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start off with binary classification.\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Note that the label column isn't named label, it's named PrivateIndex in this case.\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.4542994281045752\n"
     ]
    }
   ],
   "source": [
    "print(\"DTC\")\n",
    "print(my_binary_eval.evaluate(dtc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+--------------------+----------+\n",
      "|  features|PrivateIndex|       rawPrediction|         probability|prediction|\n",
      "+----------+------------+--------------------+--------------------+----------+\n",
      "|     [0.6]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|     [0.6]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|  [0.6408]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|    [0.72]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|  [0.8808]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|  [0.9144]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|   [0.936]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|[0.955032]|         0.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|[0.959832]|         0.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|    [0.96]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|    [0.96]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|    [0.96]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|    [0.96]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|   [1.032]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|   [1.032]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|  [1.0392]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|[1.120776]|         0.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|   [1.152]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|     [1.2]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "|     [1.2]|         2.0|[14.0,7.0,42.0,7....|[0.18918918918918...|       2.0|\n",
      "+----------+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "----------------------------------------\n",
      "A single decision tree has an accuracy of: 36.19%\n"
     ]
    }
   ],
   "source": [
    "dtc_predictions.show()\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"PrivateIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|features|PrivateIndex|\n",
      "+--------+------------+\n",
      "|   [1.2]|         2.0|\n",
      "| [1.152]|         2.0|\n",
      "| [1.152]|         2.0|\n",
      "| [1.032]|         2.0|\n",
      "| [0.936]|         2.0|\n",
      "| [0.936]|         2.0|\n",
      "|  [0.96]|         2.0|\n",
      "| [1.824]|         2.0|\n",
      "|  [1.68]|         2.0|\n",
      "| [1.872]|         2.0|\n",
      "| [1.872]|         2.0|\n",
      "| [1.872]|         2.0|\n",
      "| [1.728]|         2.0|\n",
      "| [1.728]|         2.0|\n",
      "|  [1.68]|         2.0|\n",
      "| [1.392]|         2.0|\n",
      "| [1.344]|         2.0|\n",
      "| [1.344]|         2.0|\n",
      "|  [1.44]|         2.0|\n",
      "| [1.392]|         2.0|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+\n",
      "|   mkt_name|\n",
      "+-----------+\n",
      "|Ulaanbaatar|\n",
      "|     Dornod|\n",
      "|Uvurkhangai|\n",
      "|    Selenge|\n",
      "|Bayan-Ulgii|\n",
      "+-----------+\n",
      "\n",
      "+------------+\n",
      "|PrivateIndex|\n",
      "+------------+\n",
      "|         0.0|\n",
      "|         1.0|\n",
      "|         4.0|\n",
      "|         3.0|\n",
      "|         2.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "final_data.show()\n",
    "data1.select('mkt_name').distinct().show()\n",
    "final_data.select('PrivateIndex').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4d93a6c17cb9d39467bc) of depth 5 with 37 nodes\n",
      "  If (feature 0 <= 5.9136)\n",
      "   If (feature 0 <= 3.0864)\n",
      "    If (feature 0 <= 2.7312)\n",
      "     If (feature 0 <= 1.3374)\n",
      "      Predict: 1.0\n",
      "     Else (feature 0 > 1.3374)\n",
      "      If (feature 0 <= 1.8696)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 1.8696)\n",
      "       Predict: 1.0\n",
      "    Else (feature 0 > 2.7312)\n",
      "     If (feature 0 <= 2.891904)\n",
      "      Predict: 4.0\n",
      "     Else (feature 0 > 2.891904)\n",
      "      Predict: 2.0\n",
      "   Else (feature 0 > 3.0864)\n",
      "    If (feature 0 <= 4.8)\n",
      "     If (feature 0 <= 4.08)\n",
      "      If (feature 0 <= 3.39374424)\n",
      "       Predict: 4.0\n",
      "      Else (feature 0 > 3.39374424)\n",
      "       Predict: 4.0\n",
      "     Else (feature 0 > 4.08)\n",
      "      Predict: 4.0\n",
      "    Else (feature 0 > 4.8)\n",
      "     Predict: 4.0\n",
      "  Else (feature 0 > 5.9136)\n",
      "   If (feature 0 <= 15.5784)\n",
      "    If (feature 0 <= 6.84)\n",
      "     Predict: 5.0\n",
      "    Else (feature 0 > 6.84)\n",
      "     If (feature 0 <= 12.336)\n",
      "      If (feature 0 <= 11.2008)\n",
      "       Predict: 0.0\n",
      "      Else (feature 0 > 11.2008)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 12.336)\n",
      "      If (feature 0 <= 13.548)\n",
      "       Predict: 0.0\n",
      "      Else (feature 0 > 13.548)\n",
      "       Predict: 0.0\n",
      "   Else (feature 0 > 15.5784)\n",
      "    If (feature 0 <= 18.6408)\n",
      "     If (feature 0 <= 17.5992)\n",
      "      If (feature 0 <= 16.536)\n",
      "       Predict: 3.0\n",
      "      Else (feature 0 > 16.536)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 17.5992)\n",
      "      Predict: 3.0\n",
      "    Else (feature 0 > 18.6408)\n",
      "     If (feature 0 <= 20.3184)\n",
      "      Predict: 3.0\n",
      "     Else (feature 0 > 20.3184)\n",
      "      Predict: 3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dtc_model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
