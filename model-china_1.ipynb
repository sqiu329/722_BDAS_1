{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('722-model').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1= spark.read.csv(\"./data_china.csv\", header=True, inferSchema=True)\n",
    "data1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "  inputCols=['mp_price_RMB'],\n",
    "              outputCol=\"features\")\n",
    "output = assembler.transform(data1)\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"cm_name\", outputCol=\"PrivateIndex\")\n",
    "output_fixed = indexer.fit(output).transform(output)\n",
    "final_data = output_fixed.select(\"features\",'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "dtc = DecisionTreeClassifier(labelCol='PrivateIndex',featuresCol='features')\n",
    "train_data,test_data = final_data.randomSplit([0.7,0.3])\n",
    "dtc_model = dtc.fit(train_data)\n",
    "dtc_predictions = dtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start off with binary classification.\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Note that the label column isn't named label, it's named PrivateIndex in this case.\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.7545731707317074\n"
     ]
    }
   ],
   "source": [
    "print(\"DTC\")\n",
    "print(my_binary_eval.evaluate(dtc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------------------+--------------------+----------+\n",
      "|features|PrivateIndex|       rawPrediction|         probability|prediction|\n",
      "+--------+------------+--------------------+--------------------+----------+\n",
      "| [1.315]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[1.3625]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "| [1.395]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[1.5025]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.54]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "| [1.545]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[1.5567]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.57]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.59]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[1.5975]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "| [1.615]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.62]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.62]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.63]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.63]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.63]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "| [1.645]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.65]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|  [1.65]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "| [1.655]|         1.0|[0.0,103.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "+--------+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "----------------------------------------\n",
      "A single decision tree has an accuracy of: 90.61%\n"
     ]
    }
   ],
   "source": [
    "dtc_predictions.show()\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"PrivateIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|features|PrivateIndex|\n",
      "+--------+------------+\n",
      "|[2.6567]|         3.0|\n",
      "|  [2.61]|         3.0|\n",
      "| [2.616]|         3.0|\n",
      "|  [2.57]|         3.0|\n",
      "|  [2.54]|         3.0|\n",
      "| [2.516]|         3.0|\n",
      "|  [2.54]|         3.0|\n",
      "|[2.5775]|         3.0|\n",
      "|  [2.62]|         3.0|\n",
      "|[2.6175]|         3.0|\n",
      "| [2.594]|         3.0|\n",
      "| [2.595]|         3.0|\n",
      "|   [2.6]|         3.0|\n",
      "|  [2.58]|         3.0|\n",
      "| [2.582]|         3.0|\n",
      "| [2.595]|         3.0|\n",
      "| [2.552]|         3.0|\n",
      "|  [2.47]|         3.0|\n",
      "|  [2.45]|         3.0|\n",
      "| [2.444]|         3.0|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|             cm_name|\n",
      "+--------------------+\n",
      "|Wheat flour (firs...|\n",
      "|Rice (Indica) - W...|\n",
      "|Rice (Japonica) -...|\n",
      "|   Wheat - Wholesale|\n",
      "|   Maize - Wholesale|\n",
      "+--------------------+\n",
      "\n",
      "+------------+\n",
      "|PrivateIndex|\n",
      "+------------+\n",
      "|         0.0|\n",
      "|         1.0|\n",
      "|         4.0|\n",
      "|         3.0|\n",
      "|         2.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "final_data.show()\n",
    "data1.select('cm_name').distinct().show()\n",
    "final_data.select('PrivateIndex').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_42adac62f17be4bf4032) of depth 5 with 29 nodes\n",
      "  If (feature 0 <= 3.75)\n",
      "   If (feature 0 <= 3.08)\n",
      "    If (feature 0 <= 2.2525)\n",
      "     If (feature 0 <= 1.923)\n",
      "      Predict: 1.0\n",
      "     Else (feature 0 > 1.923)\n",
      "      Predict: 1.0\n",
      "    Else (feature 0 > 2.2525)\n",
      "     If (feature 0 <= 2.325)\n",
      "      Predict: 3.0\n",
      "     Else (feature 0 > 2.325)\n",
      "      If (feature 0 <= 2.57)\n",
      "       Predict: 3.0\n",
      "      Else (feature 0 > 2.57)\n",
      "       Predict: 3.0\n",
      "   Else (feature 0 > 3.08)\n",
      "    If (feature 0 <= 3.465)\n",
      "     Predict: 2.0\n",
      "    Else (feature 0 > 3.465)\n",
      "     Predict: 2.0\n",
      "  Else (feature 0 > 3.75)\n",
      "   If (feature 0 <= 4.23)\n",
      "    If (feature 0 <= 4.1525)\n",
      "     If (feature 0 <= 3.96)\n",
      "      If (feature 0 <= 3.92)\n",
      "       Predict: 4.0\n",
      "      Else (feature 0 > 3.92)\n",
      "       Predict: 4.0\n",
      "     Else (feature 0 > 3.96)\n",
      "      If (feature 0 <= 4.0375)\n",
      "       Predict: 4.0\n",
      "      Else (feature 0 > 4.0375)\n",
      "       Predict: 4.0\n",
      "    Else (feature 0 > 4.1525)\n",
      "     Predict: 4.0\n",
      "   Else (feature 0 > 4.23)\n",
      "    If (feature 0 <= 4.36)\n",
      "     If (feature 0 <= 4.29)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 4.29)\n",
      "      Predict: 0.0\n",
      "    Else (feature 0 > 4.36)\n",
      "     Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dtc_model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
